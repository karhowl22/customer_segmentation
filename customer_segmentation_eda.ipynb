{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Customer Segmentation using Unsupervised Machine Learning\n",
        "## Part 1: Comprehensive Exploratory Data Analysis (EDA)\n",
        "\n",
        "**Objective**: Implement advanced customer segmentation using multiple unsupervised learning algorithms to identify distinct customer groups for targeted marketing strategies.\n",
        "\n",
        "**Author**: [Your Name]  \n",
        "**Course**: BMCS2003 Artificial Intelligence  \n",
        "**Assignment**: Machine Learning (Unsupervised)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Library Installation\n",
        "Installing all required libraries for advanced clustering analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for advanced clustering\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn plotly\n",
        "!pip install yellowbrick umap-learn kneed\n",
        "!pip install streamlit --quiet\n",
        "\n",
        "# Import essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Initial Inspection\n",
        "Advanced data profiling and quality assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# For Google Colab, upload the file first\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('shopping_trends.csv')\n",
        "\n",
        "print(f\"📊 Dataset Shape: {df.shape}\")\n",
        "print(f\"📅 Data loaded successfully with {df.shape[0]:,} customers and {df.shape[1]} features\")\n",
        "print(\"\\n\" + \"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive data overview\n",
        "def data_overview(df):\n",
        "    \"\"\"\n",
        "    Comprehensive data profiling function\n",
        "    \"\"\"\n",
        "    print(\"🔍 DATA OVERVIEW\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Basic info\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # Data types\n",
        "    print(\"\\n📋 Data Types:\")\n",
        "    dtype_counts = df.dtypes.value_counts()\n",
        "    for dtype, count in dtype_counts.items():\n",
        "        print(f\"  {dtype}: {count} columns\")\n",
        "    \n",
        "    # Missing values\n",
        "    print(\"\\n❌ Missing Values:\")\n",
        "    missing = df.isnull().sum()\n",
        "    if missing.sum() == 0:\n",
        "        print(\"  ✅ No missing values found!\")\n",
        "    else:\n",
        "        missing_pct = (missing / len(df)) * 100\n",
        "        missing_df = pd.DataFrame({\n",
        "            'Missing Count': missing[missing > 0],\n",
        "            'Percentage': missing_pct[missing > 0]\n",
        "        })\n",
        "        print(missing_df)\n",
        "    \n",
        "    # Duplicate rows\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"\\n🔄 Duplicate Rows: {duplicates} ({duplicates/len(df)*100:.2f}%)\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = data_overview(df)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
